# Balanced Configuration - Good Speed + Good Quality
# ~4-5 minutes for 4-min video with vocal separation + enhancement

version: 1
environment: balanced
metadata:
  config_name: Balanced Preset
  description: Good speed and good quality balance

audio_preprocessing:
  enable: true
  retain_intermediates: true

  vocal_separation:
    enable: true              # RE-ENABLED with performance optimizations
    model: "mdx_extra"        # Fast MDX model (try mdx if mdx_extra fails)
    segment_seconds: 6        # Smaller windows to cut peak RAM / avoid SIGKILL
    overlap: 0.10             # Reduce overlap for speed
    shifts: 0                 # Disable TTA for speed (0 = no extra passes)
    device: "auto"            # Prefer MPS/CUDA, else CPU
    dtype: "fp16"             # When on GPU/MPS; ignored on CPU
    timeout_seconds: 900      # 15 min timeout for safety

  enhancement:
    enable: "auto"            # Run only when SNR low / reverb high
    denoise: true
    dereverb: true
    nfe: 32                   # Half the passes for speed
    lambd: 0.5                # Gentler denoising
    tau: 0.4                  # Gentler dereverberation
    chunk_seconds: 18.0       # Keep default
    target_sample_rate: 16000  # Keep at 16kHz for Whisper compatibility
    device: "auto"            # Allow MPS, fall back to CPU if it throws
    provider: resemble
    clearervoice:
      separation_model: MossFormer2_SS_16K
      enhancement_model: FRCRN_SE_16K
      target_sample_rate: 16000

# Audio extraction
audio:
  sample_rate: 16000
  channels: 1
  codec: "pcm_s16le"
  format: "wav"
  normalization:
    target_lufs: -16.0
    loudness_range: 11.0
    true_peak: -1.0
    dual_pass: false  # Single pass for speed

# Providers (ASR, diarization, embeddings)
providers:
  whisper:
    mode: local
    model: medium
    device: cpu          # TEMP: force CPU to rule out MPS/Metal lockups
    compute_type: int8   # fast & low-mem on CPU
    download_root: ./data/models/whisper
    beam_size: 1         # reduce complexity until stable
  whisper_api:
    api_base_url: https://api.openai.com/v1/audio/transcriptions
    timeout_seconds: 600
    max_retries: 2
    model: whisper-1
    api_key_env: OPENAI_API_KEY
    organization_env: OPENAI_ORG_ID
    project_env: OPENAI_PROJECT_ID
  pyannote:
    enabled: true
    model: pyannote/speaker-diarization-3.1
    segmentation_threshold: 0.5
    auth_token_env: PYANNOTE_TOKEN
    embedding_model: pyannote/wespeaker-voxceleb-resnet34-LM
  resemblyzer:
    enabled: true
    model: resemblyzer/vad
    embedding_threshold: 0.78
    min_utterance_seconds: 1.0

# Runtime settings
runtime:
  max_workers: 2
  prefer_gpu: true
  device_priority:
    - mps
    - cpu
  ffmpeg_path: /opt/homebrew/bin/ffmpeg

# Processing settings
processing:
  resume_on_start: true
  max_episode_duration_minutes: 120
  checkpoint_interval_seconds: 300
  cleanup_temp_on_finish: true

# Transcription settings
transcription:
  language: en
  temperature: 0.0
  enable_word_timestamps: true
  initial_prompt: "Reality TV dialogue with background noise and music."
  word_timestamps_threshold: 0.4

# Diarization settings
diarization:
  min_speakers: 1
  max_speakers: 10
  onset: 0.30
  offset: 0.10
  overlap_threshold: 0.30

# Voice identification
voice_identification:
  embedding_provider: pyannote
  high_confidence_threshold: 0.85
  medium_confidence_threshold: 0.70
  low_confidence_threshold: 0.50
  auto_register_new_speakers: true
  min_samples_required: 2

# Bleeps detection
bleeps:
  enable: true
  detect_types:
    - tone
    - mute
    - noise
  tone_min_dur_ms: 80
  merge_gap_ms: 120
  min_snr_db: 10
  suggest_words: false
  use_ml_classifier: false
  confidence_threshold: 0.7

# Voice bank
voice_bank:
  auto_backup: true
  max_embeddings_per_speaker: 20
  backup_frequency_days: 7
  backup_dir: ./data/voice_bank/backups
  match_threshold: 0.82
  min_sample_duration_seconds: 1.0

# Alignment
alignment:
  max_time_diff_seconds: 0.5
  prefer_longer_segments: true

# UI settings
ui:
  streamlit:
    port: 8502
    auto_open_browser: false
    theme: dark
    layout: wide
    auto_refresh_seconds: 5
  audio_player:
    preroll_ms: 2000
    waveform_enabled: true
    keyboard_shortcuts_enabled: true

# Output formats
outputs:
  export_formats:
    - txt
    - srt
    - json
  include_confidence_scores: true
  include_word_timestamps: true
  save_intermediate_files: true

# Feature flags
features:
  auto_correct_names: true
  enable_transcript_builder: true
  enable_voice_bank: true
  enable_bleep_detection: true

# Integrations
integrations:
  slack:
    enabled: false
    webhook_url: null
    channel: null
  email:
    enabled: false
    smtp_server: null
    smtp_port: 587
    use_tls: true
    username: null
    from_address: null
    to_addresses: []

# Monitoring
monitoring:
  enable_metrics: false
  metrics_port: 9123
  capture_system_stats: true

# Cache settings
cache:
  enabled: true
  max_size_gb: 10
  cleanup_on_start: false

# Paths
paths:
  project_root: .
  data_root: ./data
  output_root: ./outputs
  cache_dir: ./data/cache
  temp_dir: ./data/tmp
  models_dir: ./data/models
  voice_bank_db: ./data/voice_bank/voice_bank.sqlite3
  logs_dir: ./logs

# Logging
logging:
  level: INFO
  rich_tracebacks: true
  json: false
  file:
    enabled: true
    path: ./logs/show-scribe.log
    rotation_mb: 10
    retention_days: 7
